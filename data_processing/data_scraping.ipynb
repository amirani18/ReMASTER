{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib as joblib\n",
    "import pickle\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# from ReMASTER.system import get_data_dir\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/11/2019 23:05</td>\n",
       "      <td>9073.25</td>\n",
       "      <td>9098.50</td>\n",
       "      <td>9073.00</td>\n",
       "      <td>9092.50</td>\n",
       "      <td>1758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/11/2019 23:10</td>\n",
       "      <td>9093.25</td>\n",
       "      <td>9095.50</td>\n",
       "      <td>9089.75</td>\n",
       "      <td>9092.75</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/11/2019 23:15</td>\n",
       "      <td>9093.00</td>\n",
       "      <td>9096.25</td>\n",
       "      <td>9088.00</td>\n",
       "      <td>9089.75</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/11/2019 23:20</td>\n",
       "      <td>9090.25</td>\n",
       "      <td>9090.25</td>\n",
       "      <td>9086.00</td>\n",
       "      <td>9087.00</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/11/2019 23:25</td>\n",
       "      <td>9086.75</td>\n",
       "      <td>9088.25</td>\n",
       "      <td>9079.75</td>\n",
       "      <td>9083.75</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time     Open     High      Low    Close  Volume\n",
       "0  8/11/2019 23:05  9073.25  9098.50  9073.00  9092.50    1758\n",
       "1  8/11/2019 23:10  9093.25  9095.50  9089.75  9092.75     438\n",
       "2  8/11/2019 23:15  9093.00  9096.25  9088.00  9089.75     590\n",
       "3  8/11/2019 23:20  9090.25  9090.25  9086.00  9087.00     278\n",
       "4  8/11/2019 23:25  9086.75  9088.25  9079.75  9083.75     711"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'C:\\\\Users\\\\amirani\\\\OneDrive - purdue.edu\\\\CSDSDATA\\\\Desktop\\\\ReMASTER\\\\data\\\\NQ_5Years_8_11_2024.csv'\n",
    "\n",
    "# Initialize an empty DataFrame for the combined data\n",
    "# data = pd.DataFrame()\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe to inspect its structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-11 23:05:00</td>\n",
       "      <td>-2.256861</td>\n",
       "      <td>1.802600</td>\n",
       "      <td>-2.130639</td>\n",
       "      <td>1.565561</td>\n",
       "      <td>2.904046</td>\n",
       "      <td>2019-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-11 23:10:00</td>\n",
       "      <td>1.334527</td>\n",
       "      <td>1.162968</td>\n",
       "      <td>1.555467</td>\n",
       "      <td>1.634445</td>\n",
       "      <td>-0.020545</td>\n",
       "      <td>2019-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-11 23:15:00</td>\n",
       "      <td>1.289635</td>\n",
       "      <td>1.322876</td>\n",
       "      <td>1.170351</td>\n",
       "      <td>0.807829</td>\n",
       "      <td>0.316226</td>\n",
       "      <td>2019-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-11 23:20:00</td>\n",
       "      <td>0.795819</td>\n",
       "      <td>0.043611</td>\n",
       "      <td>0.730219</td>\n",
       "      <td>0.050098</td>\n",
       "      <td>-0.375040</td>\n",
       "      <td>2019-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-11 23:25:00</td>\n",
       "      <td>0.167326</td>\n",
       "      <td>-0.382810</td>\n",
       "      <td>-0.645194</td>\n",
       "      <td>-0.845403</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>2019-08-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time      Open      High       Low     Close    Volume  \\\n",
       "0 2019-08-11 23:05:00 -2.256861  1.802600 -2.130639  1.565561  2.904046   \n",
       "1 2019-08-11 23:10:00  1.334527  1.162968  1.555467  1.634445 -0.020545   \n",
       "2 2019-08-11 23:15:00  1.289635  1.322876  1.170351  0.807829  0.316226   \n",
       "3 2019-08-11 23:20:00  0.795819  0.043611  0.730219  0.050098 -0.375040   \n",
       "4 2019-08-11 23:25:00  0.167326 -0.382810 -0.645194 -0.845403  0.584314   \n",
       "\n",
       "         Date  \n",
       "0  2019-08-11  \n",
       "1  2019-08-11  \n",
       "2  2019-08-11  \n",
       "3  2019-08-11  \n",
       "4  2019-08-11  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Convert 'Time' column to datetime format\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "# Step 2: Check for any NA values and drop columns with NA values (if any)\n",
    "data.dropna(axis=1, inplace=True)\n",
    "\n",
    "# Step 3: Perform robust daily Z-score normalization on each feature dimension\n",
    "# Extract date component for daily grouping\n",
    "data['Date'] = data['Time'].dt.date\n",
    "# Group by 'Date' and normalize 'Open', 'High', 'Low', 'Close', and 'Volume' columns\n",
    "feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data[feature_columns] = data.groupby('Date')[feature_columns].transform(zscore)\n",
    "\n",
    "# Step 4: Drop 5% of the most extreme values from the 'Close' column to reduce label outliers\n",
    "# Identify upper and lower 2.5% quantiles for 'Close'\n",
    "q_low, q_high = data['Close'].quantile([0.025, 0.975])\n",
    "data = data[(data['Close'] >= q_low) & (data['Close'] <= q_high)]\n",
    "\n",
    "# Step 5: Drop NA rows (if any remain after filtering) and reset index\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 6: Save the cleaned data to a new CSV file\n",
    "# Create the directory if it doesn't exist\n",
    "save_path = 'new_data/reshaped_data.csv'\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "data.to_csv(save_path, index=False)\n",
    "\n",
    "# Display first few rows of the cleaned data to confirm\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train, valid, and test sets by datetime. Earlier years are in training, recent years in test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\amirani\\\\OneDrive - purdue.edu\\\\CSDSDATA\\\\Desktop\\\\ReMASTER\\\\data\\\\NQ100\\\\NQ100_dl_train.pkl',\n",
       " 'C:\\\\Users\\\\amirani\\\\OneDrive - purdue.edu\\\\CSDSDATA\\\\Desktop\\\\ReMASTER\\\\data\\\\NQ100\\\\NQ100_dl_valid.pkl',\n",
       " 'C:\\\\Users\\\\amirani\\\\OneDrive - purdue.edu\\\\CSDSDATA\\\\Desktop\\\\ReMASTER\\\\data\\\\NQ100\\\\NQ100_dl_test.pkl')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the 'Time' column to a datetime type for sorting and splitting\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "\n",
    "# Sort the data by the datetime to ensure the time-based order is maintained\n",
    "data = data.sort_values(by='Time')\n",
    "\n",
    "# Define the split ratios for train (80%), validation (10%), and test (10%)\n",
    "train_size = int(len(data) * 0.8)\n",
    "valid_size = int(len(data) * 0.1)\n",
    "\n",
    "# Create train, validation, and test splits based on time order\n",
    "train_data = data[:train_size]\n",
    "valid_data = data[train_size:train_size + valid_size]\n",
    "test_data = data[train_size + valid_size:]\n",
    "\n",
    "# Save each set as .pkl files\n",
    "train_path = 'C:\\\\Users\\\\amirani\\\\OneDrive - purdue.edu\\\\CSDSDATA\\\\Desktop\\\\ReMASTER\\\\data\\\\NQ100\\\\NQ100_dl_train.pkl'\n",
    "valid_path = 'C:\\\\Users\\\\amirani\\\\OneDrive - purdue.edu\\\\CSDSDATA\\\\Desktop\\\\ReMASTER\\\\data\\\\NQ100\\\\NQ100_dl_valid.pkl'\n",
    "test_path = 'C:\\\\Users\\\\amirani\\\\OneDrive - purdue.edu\\\\CSDSDATA\\\\Desktop\\\\ReMASTER\\\\data\\\\NQ100\\\\NQ100_dl_test.pkl'\n",
    "\n",
    "with open(train_path, 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "with open(valid_path, 'wb') as f:\n",
    "    pickle.dump(valid_data, f)\n",
    "\n",
    "with open(test_path, 'wb') as f:\n",
    "    pickle.dump(test_data, f)\n",
    "\n",
    "train_path, valid_path, test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure data is in the .pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exists in C:\\Users\\amirani\\OneDrive - purdue.edu\\CSDSDATA\\Desktop\\ReMASTER\\data\\NQ100\\NQ100_dl_train.pkl and has 250369 rows and 7 columns.\n",
      "Data exists in C:\\Users\\amirani\\OneDrive - purdue.edu\\CSDSDATA\\Desktop\\ReMASTER\\data\\NQ100\\NQ100_dl_valid.pkl and has 31296 rows and 7 columns.\n",
      "Data exists in C:\\Users\\amirani\\OneDrive - purdue.edu\\CSDSDATA\\Desktop\\ReMASTER\\data\\NQ100\\NQ100_dl_test.pkl and has 31297 rows and 7 columns.\n"
     ]
    }
   ],
   "source": [
    "# Function to load and test if data exists in each .pkl file\n",
    "def test_data_in_pkl(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        # Check if the DataFrame is not empty\n",
    "        if isinstance(data, pd.DataFrame) and not data.empty:\n",
    "            print(f\"Data exists in {file_path} and has {len(data)} rows and {len(data.columns)} columns.\")\n",
    "        else:\n",
    "            print(f\"File {file_path} is either empty or not a DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Test each .pkl file\n",
    "test_data_in_pkl(train_path)\n",
    "test_data_in_pkl(valid_path)\n",
    "test_data_in_pkl(test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
