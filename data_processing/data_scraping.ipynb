{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/areejmirani/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib as joblib\n",
    "import pickle\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# from ReMASTER.system import get_data_dir\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/11/2019 23:05</td>\n",
       "      <td>9073.25</td>\n",
       "      <td>9098.50</td>\n",
       "      <td>9073.00</td>\n",
       "      <td>9092.50</td>\n",
       "      <td>1758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/11/2019 23:10</td>\n",
       "      <td>9093.25</td>\n",
       "      <td>9095.50</td>\n",
       "      <td>9089.75</td>\n",
       "      <td>9092.75</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/11/2019 23:15</td>\n",
       "      <td>9093.00</td>\n",
       "      <td>9096.25</td>\n",
       "      <td>9088.00</td>\n",
       "      <td>9089.75</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/11/2019 23:20</td>\n",
       "      <td>9090.25</td>\n",
       "      <td>9090.25</td>\n",
       "      <td>9086.00</td>\n",
       "      <td>9087.00</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/11/2019 23:25</td>\n",
       "      <td>9086.75</td>\n",
       "      <td>9088.25</td>\n",
       "      <td>9079.75</td>\n",
       "      <td>9083.75</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time     Open     High      Low    Close  Volume\n",
       "0  8/11/2019 23:05  9073.25  9098.50  9073.00  9092.50    1758\n",
       "1  8/11/2019 23:10  9093.25  9095.50  9089.75  9092.75     438\n",
       "2  8/11/2019 23:15  9093.00  9096.25  9088.00  9089.75     590\n",
       "3  8/11/2019 23:20  9090.25  9090.25  9086.00  9087.00     278\n",
       "4  8/11/2019 23:25  9086.75  9088.25  9079.75  9083.75     711"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/areejmirani/Desktop/ReMASTER/data/NQ_5Years_8_11_2024.csv'\n",
    "\n",
    "# Initialize an empty DataFrame for the combined data\n",
    "# data = pd.DataFrame()\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe to inspect its structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## updated method to ensure this set fits the csi300 form with alpha158 form etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from datetime import datetime\n",
    "\n",
    "# # 1. Convert 'Date' to datetime format\n",
    "# data['Date'] = pd.to_datetime(data['Time'])\n",
    "\n",
    "# # Set 'Date' as the index for time-based operations\n",
    "# data.set_index('Date', inplace=True)\n",
    "\n",
    "# # 2. Define the date ranges for the new splits (2020-2024)\n",
    "# train_end = datetime(2022, 3, 31)  # Q1 2022 ends\n",
    "# valid_start = datetime(2022, 4, 1)  # Q2 2022 starts\n",
    "# valid_end = datetime(2022, 6, 30)  # Q2 2022 ends\n",
    "# test_start = datetime(2022, 7, 1)  # Q3 2022 starts\n",
    "# test_end = datetime(2024, 12, 31)  # Q4 2024 ends\n",
    "# # \n",
    "# # 3. Create train, validation, and test sets based on the new splits\n",
    "# train_data = data[data.index <= train_end]\n",
    "# valid_data = data[(data.index >= valid_start) & (data.index <= valid_end)]\n",
    "# test_data = data[(data.index >= test_start) & (data.index <= test_end)]\n",
    "\n",
    "# # 4. Feature Engineering - Add Alpha158-like features\n",
    "# def calculate_alpha158_features(df):\n",
    "#     df['close_open'] = (df['Close'] - df['Open']) / df['Open']  # Close to Open ratio\n",
    "#     df['high_low'] = (df['High'] - df['Low']) / df['Open']  # High-Low to Open ratio\n",
    "#     df['close_open_highlow'] = (df['Close'] - df['Open']) / (df['High'] - df['Low'] + 1e-12)  # Close-Open to High-Low ratio\n",
    "#     df['high_max_open_close'] = (df['High'] - np.maximum(df['Open'], df['Close'])) / df['Open']  # High minus max(Open, Close) to Open ratio\n",
    "#     df['volume_change'] = df['Volume'].pct_change()  # Percentage change in volume\n",
    "#     return df\n",
    "\n",
    "# # Apply the feature engineering to each dataset\n",
    "# train_data = calculate_alpha158_features(train_data)\n",
    "# valid_data = calculate_alpha158_features(valid_data)\n",
    "# test_data = calculate_alpha158_features(test_data)\n",
    "\n",
    "# # 5. Lookback Window and Prediction Interval\n",
    "# lookback_window = 8  # 8 days lookback window\n",
    "# prediction_interval = 5  # 5 days prediction interval\n",
    "\n",
    "# def create_lookback_features(df, lookback_window, prediction_interval):\n",
    "#     df['ma_close'] = df['Close'].rolling(window=lookback_window).mean()  # Moving average of the closing price\n",
    "#     df['ma_volume'] = df['Volume'].rolling(window=lookback_window).mean()  # Moving average of volume\n",
    "#     df['price_change'] = df['Close'].pct_change(periods=prediction_interval)  # Percentage change in closing price over the prediction interval\n",
    "#     df['volatility'] = df['Close'].rolling(window=lookback_window).std()  # Standard deviation (volatility) over the lookback window\n",
    "#     return df\n",
    "\n",
    "# # Apply the lookback features to each dataset\n",
    "# train_data = create_lookback_features(train_data, lookback_window, prediction_interval)\n",
    "# valid_data = create_lookback_features(valid_data, lookback_window, prediction_interval)\n",
    "# test_data = create_lookback_features(test_data, lookback_window, prediction_interval)\n",
    "\n",
    "# # 6. Optional: Handle missing data (NaN) in the feature columns\n",
    "# train_data.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
    "# valid_data.fillna(method='ffill', inplace=True)\n",
    "# test_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# # 7. Optional: Scaling the features\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# features = ['close_open', 'high_low', 'close_open_highlow', 'high_max_open_close', 'volume_change', 'ma_close', 'ma_volume', 'price_change', 'volatility']\n",
    "# train_data[features] = scaler.fit_transform(train_data[features])\n",
    "# valid_data[features] = scaler.transform(valid_data[features])\n",
    "# test_data[features] = scaler.transform(test_data[features])\n",
    "\n",
    "# # 8. Save the processed datasets\n",
    "# train_data.to_csv('train_data_2020_2022.csv')\n",
    "# valid_data.to_csv('valid_data_2022.csv')\n",
    "# test_data.to_csv('test_data_2022_2024.csv')\n",
    "\n",
    "# # 9. Show the final processed data\n",
    "# print(\"Training Set:\")\n",
    "# print(train_data.head())\n",
    "# # print(\"Validation Set:\")\n",
    "# # print(valid_data.head())\n",
    "# # print(\"Test Set:\")\n",
    "# # print(test_data.head())\n",
    "\n",
    "# #10. check column names\n",
    "# print(\"training set: \")\n",
    "# print(train_data.columns)\n",
    "# # print(\"validation set: \")\n",
    "# # print(valid_data.columns)\n",
    "# # print(\"test set: \")\n",
    "# # print(test_data.columns)\n",
    "\n",
    "# #10. check datatypes\n",
    "# print(\"training set: \")\n",
    "# print(train_data.dtypes)\n",
    "# # print(\"validation set: \")\n",
    "# # print(valid_data.dtypes)\n",
    "# # print(\"test set: \")\n",
    "# # print(test_data.dtypes)\n",
    "\n",
    "# #10. check shape (len, width) \n",
    "# print(\"training set: \")\n",
    "# print(train_data.shape)\n",
    "# # print(\"validation set: \")\n",
    "# # print(valid_data.shape)\n",
    "# # print(\"test set: \")\n",
    "# # print(test_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reformat to fit multi-index and get the specified features that csi300 has\n",
    "\n",
    "this is what csi300's formulas were:\n",
    "\n",
    "MultiIndex([('feature',                              '($close-$open)/$open'),\n",
    "            ('feature',                                '($high-$low)/$open'),\n",
    "            ('feature',                 '($close-$open)/($high-$low+1e-12)'),\n",
    "            ('feature',              '($high-Greater($open, $close))/$open'),\n",
    "            ('feature', '($high-Greater($open, $close))/($high-$low+1e-12)'),\n",
    "            ('feature',                  '(Less($open, $close)-$low)/$open'),\n",
    "            ('feature',     '(Less($open, $close)-$low)/($high-$low+1e-12)'),\n",
    "            ('feature',                       '(2*$close-$high-$low)/$open'),\n",
    "            ('feature',          '(2*$close-$high-$low)/($high-$low+1e-12)'),\n",
    "            ('feature',                                      '$open/$close'),\n",
    "            ...\n",
    "            ('feature',          'Mask(Std($amount,20)/$amount,'SH000906')'),\n",
    "            ('feature',  'Mask(Mean($close/Ref($close,1)-1,30),'SH000906')'),\n",
    "            ('feature',   'Mask(Std($close/Ref($close,1)-1,30),'SH000906')'),\n",
    "            ('feature',         'Mask(Mean($amount,30)/$amount,'SH000906')'),\n",
    "            ('feature',          'Mask(Std($amount,30)/$amount,'SH000906')'),\n",
    "            ('feature',  'Mask(Mean($close/Ref($close,1)-1,60),'SH000906')'),\n",
    "            ('feature',   'Mask(Std($close/Ref($close,1)-1,60),'SH000906')'),\n",
    "            ('feature',         'Mask(Mean($amount,60)/$amount,'SH000906')'),\n",
    "            ('feature',          'Mask(Std($amount,60)/$amount,'SH000906')'),\n",
    "            (  'label',             'Ref($close, -5) / Ref($close, -1) - 1')],\n",
    "           length=222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from datetime import datetime\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # 1. Convert 'Date' to datetime format\n",
    "# data['Date'] = pd.to_datetime(data['Time'])\n",
    "\n",
    "# # Set 'Date' as the index for time-based operations\n",
    "# data.set_index('Date', inplace=True)\n",
    "\n",
    "# # 2. Define the date ranges for the new splits (2020-2024)\n",
    "# train_end = datetime(2022, 3, 31)  # Q1 2022 ends\n",
    "# valid_start = datetime(2022, 4, 1)  # Q2 2022 starts\n",
    "# valid_end = datetime(2022, 6, 30)  # Q2 2022 ends\n",
    "# test_start = datetime(2022, 7, 1)  # Q3 2022 starts\n",
    "# test_end = datetime(2024, 12, 31)  # Q4 2024 ends\n",
    "\n",
    "# # 3. Create train, validation, and test sets based on the new splits\n",
    "# train_data = data[data.index <= train_end]\n",
    "# valid_data = data[(data.index >= valid_start) & (data.index <= valid_end)]\n",
    "# test_data = data[(data.index >= test_start) & (data.index <= test_end)]\n",
    "\n",
    "# # 4. Feature Engineering - Add Alpha158-like features (more extensive)\n",
    "# def calculate_alpha158_features(df):\n",
    "#     # Basic features\n",
    "#     df['close_open'] = (df['Close'] - df['Open']) / df['Open']  # Close to Open ratio\n",
    "#     df['high_low'] = (df['High'] - df['Low']) / df['Open']  # High-Low to Open ratio\n",
    "#     df['close_open_highlow'] = (df['Close'] - df['Open']) / (df['High'] - df['Low'] + 1e-12)  # Close-Open to High-Low ratio\n",
    "#     df['high_max_open_close'] = (df['High'] - np.maximum(df['Open'], df['Close'])) / df['Open']  # High minus max(Open, Close) to Open ratio\n",
    "#     df['volume_change'] = df['Volume'].pct_change()  # Percentage change in volume\n",
    "    \n",
    "#     # Additional advanced features (based on CSI300)\n",
    "#     df['high_minus_low'] = df['High'] - df['Low']  # High-Low difference\n",
    "#     df['low_max_open_close'] = df['Low'] - np.maximum(df['Open'], df['Close'])  # Low minus max(Open, Close)\n",
    "#     df['high_to_open'] = (df['High'] - df['Open']) / df['Open']  # High to Open ratio\n",
    "#     df['low_to_open'] = (df['Low'] - df['Open']) / df['Open']  # Low to Open ratio\n",
    "#     df['close_to_high'] = (df['Close'] - df['High']) / df['High']  # Close to High ratio\n",
    "#     df['close_to_low'] = (df['Close'] - df['Low']) / df['Low']  # Close to Low ratio\n",
    "\n",
    "#     # Rolling features (Moving Averages and Volatility)\n",
    "#     df['ma_close'] = df['Close'].rolling(window=8).mean()  # 8-day moving average of Close\n",
    "#     df['ma_volume'] = df['Volume'].rolling(window=8).mean()  # 8-day moving average of Volume\n",
    "#     df['volatility'] = df['Close'].rolling(window=8).std()  # 8-day rolling standard deviation (volatility)\n",
    "#     df['price_change'] = df['Close'].pct_change(periods=5)  # 5-day percentage change in Close\n",
    "\n",
    "#     # More moving averages (longer periods)\n",
    "#     df['ma_30_close'] = df['Close'].rolling(window=30).mean()  # 30-day moving average of Close\n",
    "#     df['ma_60_close'] = df['Close'].rolling(window=60).mean()  # 60-day moving average of Close\n",
    "#     df['ma_30_volume'] = df['Volume'].rolling(window=30).mean()  # 30-day moving average of Volume\n",
    "\n",
    "#     # Adding additional feature like a ratio involving rolling standard deviation\n",
    "#     df['std_close'] = df['Close'].rolling(window=30).std()  # 30-day rolling standard deviation\n",
    "#     df['std_volume'] = df['Volume'].rolling(window=30).std()  # 30-day rolling volume standard deviation\n",
    "\n",
    "#     return df\n",
    "\n",
    "# # Apply the feature engineering to each dataset\n",
    "# train_data = calculate_alpha158_features(train_data)\n",
    "# valid_data = calculate_alpha158_features(valid_data)\n",
    "# test_data = calculate_alpha158_features(test_data)\n",
    "\n",
    "# # 5. Lookback Window and Prediction Interval (for future prediction, if needed)\n",
    "# lookback_window = 8  # 8 days lookback window\n",
    "# prediction_interval = 5  # 5 days prediction interval\n",
    "\n",
    "# def create_lookback_features(df, lookback_window, prediction_interval):\n",
    "#     df['ma_close'] = df['Close'].rolling(window=lookback_window).mean()  # Moving average of the closing price\n",
    "#     df['ma_volume'] = df['Volume'].rolling(window=lookback_window).mean()  # Moving average of volume\n",
    "#     df['price_change'] = df['Close'].pct_change(periods=prediction_interval)  # Percentage change in closing price over the prediction interval\n",
    "#     df['volatility'] = df['Close'].rolling(window=lookback_window).std()  # Standard deviation (volatility) over the lookback window\n",
    "#     return df\n",
    "\n",
    "# # Apply the lookback features to each dataset\n",
    "# train_data = create_lookback_features(train_data, lookback_window, prediction_interval)\n",
    "# valid_data = create_lookback_features(valid_data, lookback_window, prediction_interval)\n",
    "# test_data = create_lookback_features(test_data, lookback_window, prediction_interval)\n",
    "\n",
    "# # 6. Optional: Handle missing data (NaN) in the feature columns\n",
    "# train_data.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
    "# valid_data.fillna(method='ffill', inplace=True)\n",
    "# test_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# # 7. Optional: Scaling the features\n",
    "# scaler = StandardScaler()\n",
    "# features = ['close_open', 'high_low', 'close_open_highlow', 'high_max_open_close', 'volume_change', 'ma_close', 'ma_volume', 'price_change', 'volatility']\n",
    "# train_data[features] = scaler.fit_transform(train_data[features])\n",
    "# valid_data[features] = scaler.transform(valid_data[features])\n",
    "# test_data[features] = scaler.transform(test_data[features])\n",
    "\n",
    "# # 8. Feature Engineering - Adding the MultiIndex format as you requested\n",
    "# def add_multiindex_format(df):\n",
    "#     # Recompute the features in the format you provided\n",
    "#     features = ['close_open', 'high_low', 'close_open_highlow', 'high_max_open_close', 'high_max_open_close_highlow',\n",
    "#                 'high_minus_low', 'low_max_open_close', 'high_to_open', 'low_to_open', 'close_to_high', 'close_to_low',\n",
    "#                 'ma_close', 'ma_volume', 'volatility', 'price_change', 'ma_30_close', 'ma_60_close', 'ma_30_volume',\n",
    "#                 'std_close', 'std_volume']\n",
    "\n",
    "#     df_features = df[features]\n",
    "\n",
    "#     # Now, we'll change the column format to MultiIndex\n",
    "#     columns = pd.MultiIndex.from_tuples([('feature', col) for col in df_features.columns])\n",
    "\n",
    "#     # Assign this MultiIndex to the dataframe\n",
    "#     df_features.columns = columns\n",
    "\n",
    "#     return df_features\n",
    "\n",
    "# # Apply the MultiIndex formatting to the datasets\n",
    "# train_data = add_multiindex_format(train_data)\n",
    "# valid_data = add_multiindex_format(valid_data)\n",
    "# test_data = add_multiindex_format(test_data)\n",
    "\n",
    "# # 9. Save the processed datasets (after formatting)\n",
    "# train_data.to_csv('train_data_2020_2022.csv')\n",
    "# valid_data.to_csv('valid_data_2022.csv')\n",
    "# test_data.to_csv('test_data_2022_2024.csv')\n",
    "\n",
    "# # 10. Show the final processed data\n",
    "# print(\"Training Set:\")\n",
    "# print(train_data.head())\n",
    "\n",
    "# # 11. Check column names and datatypes\n",
    "# print(\"Training set columns: \")\n",
    "# print(train_data.columns)\n",
    "# print(\"Training set datatypes: \")\n",
    "# print(train_data.dtypes)\n",
    "\n",
    "# # 12. Check shape (len, width)\n",
    "# print(\"Training set shape: \")\n",
    "# print(train_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make it multi-index for features and labels like the csi300 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['(close-open)/open'] = (df['Close'] - df['Open']) / df['Open']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['(high-low)/open'] = (df['High'] - df['Low']) / df['Open']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['(2*close-high-low)/open'] = (2 * df['Close'] - df['High'] - df['Low']) / df['Open']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(close,5)/close'] = df['Close'].rolling(window=5).mean() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(close,10)/close'] = df['Close'].rolling(window=10).mean() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(close,20)/close'] = df['Close'].rolling(window=20).mean() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(close,5)/close'] = df['Close'].rolling(window=5).std() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(close,10)/close'] = df['Close'].rolling(window=10).std() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(close,20)/close'] = df['Close'].rolling(window=20).std() / df['Close']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Change Ratios done\n",
      "Moving Averages and Standard Deviations done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['VWAP/close'] = (df['Volume'] * df['Close']).cumsum() / df['Volume'].cumsum() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(volume,5)/(volume+1e-12)'] = df['Volume'].rolling(window=5).mean() / (df['Volume'] + 1e-12)\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(volume,5)/(volume+1e-12)'] = df['Volume'].rolling(window=5).std() / (df['Volume'] + 1e-12)\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Ref(close,5)/close'] = df['Close'].shift(5) / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Ref(close,10)/close'] = df['Close'].shift(10) / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Ref(close,20)/close'] = df['Close'].shift(20) / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Corr(close,log(volume+1),5)'] = df['Close'].rolling(window=5).corr(np.log(df['Volume'] + 1))\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Corr(close/Ref(close,1),log(volume/Ref(volume,1)+1),5)'] = (\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Max(high,5)/close'] = df['High'].rolling(window=5).max() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Min(low,5)/close'] = df['Low'].rolling(window=5).min() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'] = df['Close'].shift(-5) / df['Close'].shift(-1) - 1  # Ref($close, -5) / Ref($close, -1) - 1\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['(close-open)/open'] = (df['Close'] - df['Open']) / df['Open']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['(high-low)/open'] = (df['High'] - df['Low']) / df['Open']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['(2*close-high-low)/open'] = (2 * df['Close'] - df['High'] - df['Low']) / df['Open']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(close,5)/close'] = df['Close'].rolling(window=5).mean() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(close,10)/close'] = df['Close'].rolling(window=10).mean() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(close,20)/close'] = df['Close'].rolling(window=20).mean() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(close,5)/close'] = df['Close'].rolling(window=5).std() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(close,10)/close'] = df['Close'].rolling(window=10).std() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(close,20)/close'] = df['Close'].rolling(window=20).std() / df['Close']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Strength and Trends done\n",
      "Volume-Weighted Measures done\n",
      "Historical Close Ratios done\n",
      "Correlation Measures done\n",
      "Price Extremes and Ratios done\n",
      "Price Change Ratios done\n",
      "Moving Averages and Standard Deviations done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['VWAP/close'] = (df['Volume'] * df['Close']).cumsum() / df['Volume'].cumsum() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(volume,5)/(volume+1e-12)'] = df['Volume'].rolling(window=5).mean() / (df['Volume'] + 1e-12)\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(volume,5)/(volume+1e-12)'] = df['Volume'].rolling(window=5).std() / (df['Volume'] + 1e-12)\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Ref(close,5)/close'] = df['Close'].shift(5) / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Ref(close,10)/close'] = df['Close'].shift(10) / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Ref(close,20)/close'] = df['Close'].shift(20) / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Corr(close,log(volume+1),5)'] = df['Close'].rolling(window=5).corr(np.log(df['Volume'] + 1))\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Corr(close/Ref(close,1),log(volume/Ref(volume,1)+1),5)'] = (\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Max(high,5)/close'] = df['High'].rolling(window=5).max() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Min(low,5)/close'] = df['Low'].rolling(window=5).min() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'] = df['Close'].shift(-5) / df['Close'].shift(-1) - 1  # Ref($close, -5) / Ref($close, -1) - 1\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['(close-open)/open'] = (df['Close'] - df['Open']) / df['Open']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['(high-low)/open'] = (df['High'] - df['Low']) / df['Open']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['(2*close-high-low)/open'] = (2 * df['Close'] - df['High'] - df['Low']) / df['Open']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(close,5)/close'] = df['Close'].rolling(window=5).mean() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(close,10)/close'] = df['Close'].rolling(window=10).mean() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(close,20)/close'] = df['Close'].rolling(window=20).mean() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(close,5)/close'] = df['Close'].rolling(window=5).std() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(close,10)/close'] = df['Close'].rolling(window=10).std() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(close,20)/close'] = df['Close'].rolling(window=20).std() / df['Close']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Strength and Trends done\n",
      "Volume-Weighted Measures done\n",
      "Historical Close Ratios done\n",
      "Correlation Measures done\n",
      "Price Extremes and Ratios done\n",
      "Price Change Ratios done\n",
      "Moving Averages and Standard Deviations done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['VWAP/close'] = (df['Volume'] * df['Close']).cumsum() / df['Volume'].cumsum() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Mean(volume,5)/(volume+1e-12)'] = df['Volume'].rolling(window=5).mean() / (df['Volume'] + 1e-12)\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Std(volume,5)/(volume+1e-12)'] = df['Volume'].rolling(window=5).std() / (df['Volume'] + 1e-12)\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Ref(close,5)/close'] = df['Close'].shift(5) / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Ref(close,10)/close'] = df['Close'].shift(10) / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Ref(close,20)/close'] = df['Close'].shift(20) / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Corr(close,log(volume+1),5)'] = df['Close'].rolling(window=5).corr(np.log(df['Volume'] + 1))\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Corr(close/Ref(close,1),log(volume/Ref(volume,1)+1),5)'] = (\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Max(high,5)/close'] = df['High'].rolling(window=5).max() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Min(low,5)/close'] = df['Low'].rolling(window=5).min() / df['Close']\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'] = df['Close'].shift(-5) / df['Close'].shift(-1) - 1  # Ref($close, -5) / Ref($close, -1) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Strength and Trends done\n",
      "Volume-Weighted Measures done\n",
      "Historical Close Ratios done\n",
      "Correlation Measures done\n",
      "Price Extremes and Ratios done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_data.fillna(method='ffill', inplace=True)\n",
      "/var/folders/xr/hlsgwx1x76v65d6rn3zzw6vc0000gn/T/ipykernel_20704/2770355516.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "                             feature                                      \\\n",
      "                                Time     Open     High      Low    Close   \n",
      "Date                                                                       \n",
      "2019-08-11 23:05:00  8/11/2019 23:05  9073.25  9098.50  9073.00  9092.50   \n",
      "2019-08-11 23:10:00  8/11/2019 23:10  9093.25  9095.50  9089.75  9092.75   \n",
      "2019-08-11 23:15:00  8/11/2019 23:15  9093.00  9096.25  9088.00  9089.75   \n",
      "2019-08-11 23:20:00  8/11/2019 23:20  9090.25  9090.25  9086.00  9087.00   \n",
      "2019-08-11 23:25:00  8/11/2019 23:25  9086.75  9088.25  9079.75  9083.75   \n",
      "\n",
      "                                                              \\\n",
      "                    Volume (close-open)/open (high-low)/open   \n",
      "Date                                                           \n",
      "2019-08-11 23:05:00   1758          0.002122        0.002810   \n",
      "2019-08-11 23:10:00    438         -0.000055        0.000632   \n",
      "2019-08-11 23:15:00    590         -0.000357        0.000907   \n",
      "2019-08-11 23:20:00    278         -0.000358        0.000468   \n",
      "2019-08-11 23:25:00    711         -0.000330        0.000935   \n",
      "\n",
      "                                                                 ...  \\\n",
      "                    (2*close-high-low)/open Mean(close,5)/close  ...   \n",
      "Date                                                             ...   \n",
      "2019-08-11 23:05:00                0.001488                 NaN  ...   \n",
      "2019-08-11 23:10:00                0.000027                 NaN  ...   \n",
      "2019-08-11 23:15:00               -0.000522                 NaN  ...   \n",
      "2019-08-11 23:20:00               -0.000248                 NaN  ...   \n",
      "2019-08-11 23:25:00               -0.000055            1.000594  ...   \n",
      "\n",
      "                                                   \\\n",
      "                    Mean(volume,5)/(volume+1e-12)   \n",
      "Date                                                \n",
      "2019-08-11 23:05:00                           NaN   \n",
      "2019-08-11 23:10:00                           NaN   \n",
      "2019-08-11 23:15:00                           NaN   \n",
      "2019-08-11 23:20:00                           NaN   \n",
      "2019-08-11 23:25:00                      1.061885   \n",
      "\n",
      "                                                                     \\\n",
      "                    Std(volume,5)/(volume+1e-12) Ref(close,5)/close   \n",
      "Date                                                                  \n",
      "2019-08-11 23:05:00                          NaN                NaN   \n",
      "2019-08-11 23:10:00                          NaN                NaN   \n",
      "2019-08-11 23:15:00                          NaN                NaN   \n",
      "2019-08-11 23:20:00                          NaN                NaN   \n",
      "2019-08-11 23:25:00                     0.821066                NaN   \n",
      "\n",
      "                                                             \\\n",
      "                    Ref(close,10)/close Ref(close,20)/close   \n",
      "Date                                                          \n",
      "2019-08-11 23:05:00                 NaN                 NaN   \n",
      "2019-08-11 23:10:00                 NaN                 NaN   \n",
      "2019-08-11 23:15:00                 NaN                 NaN   \n",
      "2019-08-11 23:20:00                 NaN                 NaN   \n",
      "2019-08-11 23:25:00                 NaN                 NaN   \n",
      "\n",
      "                                                 \\\n",
      "                    Corr(close,log(volume+1),5)   \n",
      "Date                                              \n",
      "2019-08-11 23:05:00                         NaN   \n",
      "2019-08-11 23:10:00                         NaN   \n",
      "2019-08-11 23:15:00                         NaN   \n",
      "2019-08-11 23:20:00                         NaN   \n",
      "2019-08-11 23:25:00                     0.30595   \n",
      "\n",
      "                                                                            \\\n",
      "                    Corr(close/Ref(close,1),log(volume/Ref(volume,1)+1),5)   \n",
      "Date                                                                         \n",
      "2019-08-11 23:05:00                                                NaN       \n",
      "2019-08-11 23:10:00                                                NaN       \n",
      "2019-08-11 23:15:00                                                NaN       \n",
      "2019-08-11 23:20:00                                                NaN       \n",
      "2019-08-11 23:25:00                                                NaN       \n",
      "\n",
      "                                                        \\\n",
      "                    Max(high,5)/close Min(low,5)/close   \n",
      "Date                                                     \n",
      "2019-08-11 23:05:00               NaN              NaN   \n",
      "2019-08-11 23:10:00               NaN              NaN   \n",
      "2019-08-11 23:15:00               NaN              NaN   \n",
      "2019-08-11 23:20:00               NaN              NaN   \n",
      "2019-08-11 23:25:00          1.001624         0.998817   \n",
      "\n",
      "                                                    label  \n",
      "                    Ref($close, -5) / Ref($close, -1) - 1  \n",
      "Date                                                       \n",
      "2019-08-11 23:05:00                             -0.001127  \n",
      "2019-08-11 23:10:00                             -0.000908  \n",
      "2019-08-11 23:15:00                             -0.000248  \n",
      "2019-08-11 23:20:00                              0.000578  \n",
      "2019-08-11 23:25:00                              0.000440  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "Training set columns: \n",
      "MultiIndex([('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            ('feature', ...),\n",
      "            (  'label', ...)],\n",
      "           )\n",
      "Training set datatypes: \n",
      "feature  Time                                                       object\n",
      "         Open                                                      float64\n",
      "         High                                                      float64\n",
      "         Low                                                       float64\n",
      "         Close                                                     float64\n",
      "         Volume                                                      int64\n",
      "         (close-open)/open                                         float64\n",
      "         (high-low)/open                                           float64\n",
      "         (2*close-high-low)/open                                   float64\n",
      "         Mean(close,5)/close                                       float64\n",
      "         Mean(close,10)/close                                      float64\n",
      "         Mean(close,20)/close                                      float64\n",
      "         Std(close,5)/close                                        float64\n",
      "         Std(close,10)/close                                       float64\n",
      "         Std(close,20)/close                                       float64\n",
      "         Slope(close,5)/close                                      float64\n",
      "         Slope(close,10)/close                                     float64\n",
      "         Slope(close,20)/close                                     float64\n",
      "         VWAP/close                                                float64\n",
      "         Mean(volume,5)/(volume+1e-12)                             float64\n",
      "         Std(volume,5)/(volume+1e-12)                              float64\n",
      "         Ref(close,5)/close                                        float64\n",
      "         Ref(close,10)/close                                       float64\n",
      "         Ref(close,20)/close                                       float64\n",
      "         Corr(close,log(volume+1),5)                               float64\n",
      "         Corr(close/Ref(close,1),log(volume/Ref(volume,1)+1),5)    float64\n",
      "         Max(high,5)/close                                         float64\n",
      "         Min(low,5)/close                                          float64\n",
      "label    Ref($close, -5) / Ref($close, -1) - 1                     float64\n",
      "dtype: object\n",
      "Training set shape: \n",
      "(170738, 29)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# 1. Convert 'Date' to datetime format\n",
    "data['Date'] = pd.to_datetime(data['Time'])\n",
    "\n",
    "# Set 'Date' as the index for time-based operations\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# 2. Define the date ranges for the new splits (2020-2024)\n",
    "train_end = datetime(2022, 3, 31)  # Q1 2022 ends\n",
    "valid_start = datetime(2022, 4, 1)  # Q2 2022 starts\n",
    "valid_end = datetime(2022, 6, 30)  # Q2 2022 ends\n",
    "test_start = datetime(2022, 7, 1)  # Q3 2022 starts\n",
    "test_end = datetime(2024, 12, 31)  # Q4 2024 ends\n",
    "\n",
    "# 3. Create train, validation, and test sets based on the new splits\n",
    "train_data = data[data.index <= train_end]\n",
    "valid_data = data[(data.index >= valid_start) & (data.index <= valid_end)]\n",
    "test_data = data[(data.index >= test_start) & (data.index <= test_end)]\n",
    "\n",
    "# 4. Feature Engineering - Add CSI300-like features. CHOOSE 22 FEATURES\n",
    "def calculate_csi300_features(df):\n",
    "    # Basic features matching CSI300 format\n",
    "\n",
    "    # Price Change Ratios\n",
    "    df['(close-open)/open'] = (df['Close'] - df['Open']) / df['Open']\n",
    "    df['(high-low)/open'] = (df['High'] - df['Low']) / df['Open']\n",
    "    df['(2*close-high-low)/open'] = (2 * df['Close'] - df['High'] - df['Low']) / df['Open']\n",
    "    print(\"Price Change Ratios done\")\n",
    "    \n",
    "    # Moving Averages and Standard Deviations (Volatility)\n",
    "    df['Mean(close,5)/close'] = df['Close'].rolling(window=5).mean() / df['Close']\n",
    "    df['Mean(close,10)/close'] = df['Close'].rolling(window=10).mean() / df['Close']\n",
    "    df['Mean(close,20)/close'] = df['Close'].rolling(window=20).mean() / df['Close']\n",
    "    df['Std(close,5)/close'] = df['Close'].rolling(window=5).std() / df['Close']\n",
    "    df['Std(close,10)/close'] = df['Close'].rolling(window=10).std() / df['Close']\n",
    "    df['Std(close,20)/close'] = df['Close'].rolling(window=20).std() / df['Close']\n",
    "    print(\"Moving Averages and Standard Deviations done\")\n",
    "\n",
    "    # Relative Strength and Trends (Slope calculation)\n",
    "    for window in [5, 10, 20]:\n",
    "        df[f'Slope(close,{window})/close'] = df['Close'].rolling(window).apply(\n",
    "            lambda x: linregress(range(len(x)), x).slope / x[-1] if len(x) == window else np.nan\n",
    "        )\n",
    "    print(\"Relative Strength and Trends done\")\n",
    "\n",
    "    # Volume-Weighted Measures\n",
    "    df['VWAP/close'] = (df['Volume'] * df['Close']).cumsum() / df['Volume'].cumsum() / df['Close']\n",
    "    df['Mean(volume,5)/(volume+1e-12)'] = df['Volume'].rolling(window=5).mean() / (df['Volume'] + 1e-12)\n",
    "    df['Std(volume,5)/(volume+1e-12)'] = df['Volume'].rolling(window=5).std() / (df['Volume'] + 1e-12)\n",
    "    print(\"Volume-Weighted Measures done\")\n",
    "\n",
    "    # Historical Close Ratios\n",
    "    df['Ref(close,5)/close'] = df['Close'].shift(5) / df['Close']\n",
    "    df['Ref(close,10)/close'] = df['Close'].shift(10) / df['Close']\n",
    "    df['Ref(close,20)/close'] = df['Close'].shift(20) / df['Close']\n",
    "    print(\"Historical Close Ratios done\")\n",
    "\n",
    "    # Correlation Measures\n",
    "    df['Corr(close,log(volume+1),5)'] = df['Close'].rolling(window=5).corr(np.log(df['Volume'] + 1))\n",
    "    df['Corr(close/Ref(close,1),log(volume/Ref(volume,1)+1),5)'] = (\n",
    "        (df['Close'] / df['Close'].shift(1)).rolling(window=5)\n",
    "        .corr(np.log(df['Volume'] / df['Volume'].shift(1) + 1))\n",
    "    )\n",
    "    print(\"Correlation Measures done\")\n",
    "\n",
    "    # Price Extremes and Ratios\n",
    "    df['Max(high,5)/close'] = df['High'].rolling(window=5).max() / df['Close']\n",
    "    df['Min(low,5)/close'] = df['Low'].rolling(window=5).min() / df['Close']\n",
    "    print(\"Price Extremes and Ratios done\")\n",
    "\n",
    "    # 6. Add target label (future reference)\n",
    "    df['label'] = df['Close'].shift(-5) / df['Close'].shift(-1) - 1  # Ref($close, -5) / Ref($close, -1) - 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the feature engineering to each dataset\n",
    "train_data = calculate_csi300_features(train_data)\n",
    "valid_data = calculate_csi300_features(valid_data)\n",
    "test_data = calculate_csi300_features(test_data)\n",
    "\n",
    "# 7. Optional: Handle missing data (NaN) in the feature columns\n",
    "train_data.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
    "valid_data.fillna(method='ffill', inplace=True)\n",
    "test_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# 8. Format the dataframe to MultiIndex\n",
    "def format_to_multiindex(df):\n",
    "    # Define the MultiIndex for features\n",
    "    columns = pd.MultiIndex.from_tuples([('feature', col) for col in df.columns if col != 'label'] + [('label', 'Ref($close, -5) / Ref($close, -1) - 1')])\n",
    "    # Assign this MultiIndex to the dataframe\n",
    "    df.columns = columns\n",
    "    return df\n",
    "\n",
    "# Apply MultiIndex formatting\n",
    "train_data = format_to_multiindex(train_data)\n",
    "valid_data = format_to_multiindex(valid_data)\n",
    "test_data = format_to_multiindex(test_data)\n",
    "\n",
    "# 9. Save the processed datasets\n",
    "train_data.to_csv('train_data_2020_2022_NQ100.csv')\n",
    "valid_data.to_csv('valid_data_2022_NQ100.csv')\n",
    "test_data.to_csv('test_data_2022_2024_NQ100.csv')\n",
    "\n",
    "# 10. Show the final processed data\n",
    "print(\"Training Set:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# 11. Check column names and datatypes\n",
    "print(\"Training set columns: \")\n",
    "print(train_data.columns)\n",
    "print(\"Training set datatypes: \")\n",
    "print(train_data.dtypes)\n",
    "\n",
    "# 12. Check shape (len, width)\n",
    "print(\"Training set shape: \")\n",
    "print(train_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to .pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_train.pkl',\n",
       " '/Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_valid.pkl',\n",
       " '/Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_test.pkl')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Save each set as .pkl files\n",
    "train_path = '/Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_train.pkl'\n",
    "valid_path = '/Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_valid.pkl'\n",
    "test_path = '/Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_test.pkl'\n",
    "\n",
    "# Save train data\n",
    "with open(train_path, 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "# Save validation data\n",
    "with open(valid_path, 'wb') as f:\n",
    "    pickle.dump(valid_data, f)\n",
    "\n",
    "# Save test data\n",
    "with open(test_path, 'wb') as f:\n",
    "    pickle.dump(test_data, f)\n",
    "\n",
    "# Return the paths (optional)\n",
    "train_path, valid_path, test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensure pkl files have content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exists in /Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_train.pkl and has 170738 rows and 29 columns.\n",
      "Data exists in /Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_valid.pkl and has 15723 rows and 29 columns.\n",
      "Data exists in /Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_test.pkl and has 142469 rows and 29 columns.\n"
     ]
    }
   ],
   "source": [
    "# Function to load and test if data exists in each .pkl file\n",
    "def test_data_in_pkl(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        # Check if the DataFrame is not empty\n",
    "        if isinstance(data, pd.DataFrame) and not data.empty:\n",
    "            print(f\"Data exists in {file_path} and has {len(data)} rows and {len(data.columns)} columns.\")\n",
    "        else:\n",
    "            print(f\"File {file_path} is either empty or not a DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Test each .pkl file\n",
    "test_data_in_pkl(train_path)\n",
    "test_data_in_pkl(valid_path)\n",
    "test_data_in_pkl(test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Convert 'Time' column to datetime format\n",
    "# data['Time'] = pd.to_datetime(data['Time'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "# # Step 2: Check for any NA values and drop columns with NA values (if any)\n",
    "# data.dropna(axis=1, inplace=True)\n",
    "\n",
    "# # Step 3: Perform robust daily Z-score normalization on each feature dimension\n",
    "# # Extract date component for daily grouping\n",
    "# data['Date'] = data['Time'].dt.date\n",
    "# # Group by 'Date' and normalize 'Open', 'High', 'Low', 'Close', and 'Volume' columns\n",
    "# feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "# data[feature_columns] = data.groupby('Date')[feature_columns].transform(zscore)\n",
    "\n",
    "# # Step 4: Drop 5% of the most extreme values from the 'Close' column to reduce label outliers\n",
    "# # Identify upper and lower 2.5% quantiles for 'Close'\n",
    "# q_low, q_high = data['Close'].quantile([0.025, 0.975])\n",
    "# data = data[(data['Close'] >= q_low) & (data['Close'] <= q_high)]\n",
    "\n",
    "# # Step 5: Drop NA rows (if any remain after filtering) and reset index\n",
    "# data.dropna(inplace=True)\n",
    "# data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Step 6: Save the cleaned data to a new CSV file\n",
    "# # Create the directory if it doesn't exist\n",
    "# save_path = 'new_data/reshaped_data.csv'\n",
    "# os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "# data.to_csv(save_path, index=False)\n",
    "\n",
    "# # Display first few rows of the cleaned data to confirm\n",
    "# data.head()\n",
    "\n",
    "# print(data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train, valid, and test sets by datetime. Earlier years are in training, recent years in test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pickle\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming 'data' is your original dataframe with columns like 'Date', 'Time', 'Open', 'High', 'Low', 'Close', etc.\n",
    "\n",
    "# # 1. Combine Date and Time into a single 'datetime' column\n",
    "# # Ensure that 'Date' is a string or datetime type and 'Time' is a string (e.g., \"HH:MM:SS\")\n",
    "\n",
    "# # Convert 'Date' to datetime (if not already in datetime format)\n",
    "# data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# # Check the type of 'Time' column to handle it accordingly\n",
    "# if data['Time'].dtype == 'datetime64[ns]':  # If Time is already in datetime64[ns]\n",
    "#     data['Time'] = data['Time'].dt.time  # Extract the time part only\n",
    "# else:  # If Time is a string like 'HH:MM:SS'\n",
    "#     data['Time'] = pd.to_timedelta(data['Time'], errors='coerce')\n",
    "\n",
    "# # Combine 'Date' and 'Time' into a single 'datetime' column\n",
    "# data['datetime'] = data['Date'] + pd.to_timedelta(data['Time'].astype(str))\n",
    "\n",
    "# # Drop the original 'Date' and 'Time' columns if no longer needed\n",
    "# data.drop(columns=['Date', 'Time'], inplace=True)\n",
    "\n",
    "# # 2. Feature Engineering\n",
    "# data['close_open'] = (data['Close'] - data['Open']) / data['Open']\n",
    "# data['high_low'] = (data['High'] - data['Low']) / data['Open']\n",
    "# data['close_open_highlow'] = (data['Close'] - data['Open']) / (data['High'] - data['Low'] + 1e-12)\n",
    "# data['high_max_open_close'] = (data['High'] - data[['Open', 'Close']].max(axis=1)) / data['Open']\n",
    "\n",
    "# # 3. Handle NaN or infinite values\n",
    "# # Replace NaN with the column mean, or you can use other strategies\n",
    "# data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# # Replace any infinity values with a large number or NaN\n",
    "# data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# # Reapply fillna to handle any NaNs created by infinities\n",
    "# data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# # 4. Normalize the newly created features\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Select columns for scaling\n",
    "# features = ['close_open', 'high_low', 'close_open_highlow', 'high_max_open_close']\n",
    "# data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# # 5. Split the data into train, valid, and test\n",
    "# train_size = int(0.7 * len(data))  # 70% for training\n",
    "# valid_size = int(0.15 * len(data))  # 15% for validation\n",
    "# test_size = len(data) - train_size - valid_size  # 15% for testing\n",
    "\n",
    "# train_data = data[:train_size]\n",
    "# valid_data = data[train_size:train_size + valid_size]\n",
    "# test_data = data[train_size + valid_size:]\n",
    "\n",
    "# # 6. Save each set as .pkl files\n",
    "# train_path = '/Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_train.pkl'\n",
    "# valid_path = '/Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_valid.pkl'\n",
    "# test_path = '/Users/areejmirani/Desktop/ReMASTER/data/NQ100/NQ100_dl_test.pkl'\n",
    "\n",
    "# # Save train data\n",
    "# with open(train_path, 'wb') as f:\n",
    "#     pickle.dump(train_data, f)\n",
    "\n",
    "# # Save validation data\n",
    "# with open(valid_path, 'wb') as f:\n",
    "#     pickle.dump(valid_data, f)\n",
    "\n",
    "# # Save test data\n",
    "# with open(test_path, 'wb') as f:\n",
    "#     pickle.dump(test_data, f)\n",
    "\n",
    "# # Return the paths (optional)\n",
    "# train_path, valid_path, test_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure data is in the .pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to load and test if data exists in each .pkl file\n",
    "# def test_data_in_pkl(file_path):\n",
    "#     try:\n",
    "#         with open(file_path, 'rb') as f:\n",
    "#             data = pickle.load(f)\n",
    "#         # Check if the DataFrame is not empty\n",
    "#         if isinstance(data, pd.DataFrame) and not data.empty:\n",
    "#             print(f\"Data exists in {file_path} and has {len(data)} rows and {len(data.columns)} columns.\")\n",
    "#         else:\n",
    "#             print(f\"File {file_path} is either empty or not a DataFrame.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# # Test each .pkl file\n",
    "# test_data_in_pkl(train_path)\n",
    "# test_data_in_pkl(valid_path)\n",
    "# test_data_in_pkl(test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
